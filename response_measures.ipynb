{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0d1135e85b24d6fc36dc6a0cb37a446f4ea6c1d1c5d9ce7e53624fd1bcca00fa0",
   "display_name": "Python 3.8.0 64-bit ('epidemics': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Response measure models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load relevant libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "rs = 10"
   ]
  },
  {
   "source": [
    "## Training data\n",
    "Get training data generated from https://www.kaggle.com/josephassaker/covid19-global-dataset?select=worldometer_coronavirus_daily_data.csv. All features are calculated per 100k in the given country.\n",
    "\n",
    "### Features:\n",
    "- *country*: Country for which the data is registered for\n",
    "- *date*: Entry date for registered data\n",
    "- *active_cases*: Number of active cases of COVID-19 for the given date and country\n",
    "- *cumulative_total_cases*: Number of cumulative cases up to the given date for the given country\n",
    "- *cases_past_week*: Sum of registered cases of COVID-19 the past week (-7 days < t <= current date) for the given date and country\n",
    "- *cases_2w_ago*: Sum of registered cases of COVID-19 for the previous week (-14 days < t <= -7 days) for the given date and country\n",
    "- *cumulative_total_deaths*: Number of cumulative deaths up to the given date for the given country\n",
    "- *deaths_past_week*: Sum of registered deaths from COVID-19 the past week (-7 days < t <= current date) for the given date and country\n",
    "- *deaths_2w_ago*: Sum of registered deaths from COVID-19 for the previous week (-14 days < t <= -7 days) for the given date and country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('data/response_measures/training_data_response_measures.csv', parse_dates=['date']).drop(columns=['response_measures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 106712 entries, 0 to 106711\nData columns (total 9 columns):\n #   Column                   Non-Null Count   Dtype         \n---  ------                   --------------   -----         \n 0   date                     106712 non-null  datetime64[ns]\n 1   country                  106712 non-null  object        \n 2   active_cases             106712 non-null  float64       \n 3   cumulative_total_cases   106712 non-null  float64       \n 4   cases_past_week          106712 non-null  float64       \n 5   cases_2w_ago             106712 non-null  float64       \n 6   cumulative_total_deaths  106712 non-null  float64       \n 7   deaths_past_week         106712 non-null  float64       \n 8   deaths_2w_ago            106712 non-null  float64       \ndtypes: datetime64[ns](1), float64(7), object(1)\nmemory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_training.info()"
   ]
  },
  {
   "source": [
    "## Target data\n",
    "Use data from https://ourworldindata.org/policy-responses-covid to retrieve target response data for the models. Data exists between 2020-01-01 to 2021-04-29.\n",
    "\n",
    "### Stringency\n",
    "This is a composite measure based on nine response indicators including school closures, workplace closures, and\n",
    "travel bans, rescaled to a value from 0 to 100 (100 = strictest). The nine metrics used to calculate the Stringency Index are: school closures; workplace closures; cancellation of public events; restrictions on public gatherings; closures of public transport; stay-at-home requirements; public information campaigns; restrictions on internal movements; and international travel controls. It’s important to note that this index simply records the strictness of government policies. It does not measure or imply the appropriateness or effectiveness of a country’s response. A higher score does not necessarily mean that a country’s response is ‘better’ than others lower on the index.\n",
    "\n",
    "### Internal movement\n",
    "Restrictions on internal movement during the COVID-19 pandemic. The measures are classified in the range 0-2:\n",
    "- **0**: No measures\n",
    "- **1**: Recommend movement restriction\n",
    "- **2**: Restrict movement\n",
    "\n",
    "### Public gatherings\n",
    "Restrictions on public gatherings in the COVID-19 pandemic. Restrictions are given based on the size of public gatherings as follows:\n",
    "- **0**: No measures\n",
    "- **1**: Restrictions on very large gatherings (the limit is above 1000 people)\n",
    "- **2**: gatherings between 100-1000 people\n",
    "- **3**: gatherings between 10-100 people\n",
    "- **4**: gatherings of less than 10 people\n",
    "\n",
    "### School\n",
    "School closures during the COVID-19 pandemic. The measures are classified in the range 0-3:\n",
    "- **0**: No measures\n",
    "- **1**: Recommended\n",
    "- **2**: Required (only at some levels)\n",
    "- **3**: Required (all levels)\n",
    "\n",
    "### Workplace\n",
    "Workplace closures during the COVID-19 pandemic. The measures are classified in the range 0-3:\n",
    "- **0**: No measures\n",
    "- **1**: Recommended\n",
    "- **2**: Required for some\n",
    "- **3**: Required for all but key workers\n",
    "\n",
    "### Home\n",
    "Stay-at-home requirements during the COVID-19 pandemic. The measures are classified in the range 0-3:\n",
    "- **0**: No measures\n",
    "- **1**: Recommended not to leave the house\n",
    "- **2**: Required to not leave the house with exceptions for daily exercise, grocery shopping, and ‘essential’ trips\n",
    "- **3**: Required to not leave the house with minimal exceptions (e.g. allowed to leave only once every few days, or only one person can leave at a time, etc.)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stringency = pd.read_csv('data/response_measures/covid-stringency-index.csv', parse_dates=['date'])\n",
    "df_internal_movement = pd.read_csv('data/response_measures/internal-movement-covid.csv', parse_dates=['date'])\n",
    "df_public_gathering = pd.read_csv('data/response_measures/public-gathering-rules-covid.csv', parse_dates=['date'])\n",
    "df_school = pd.read_csv('data/response_measures/school-closures-covid.csv', parse_dates=['date'])\n",
    "df_workplace = pd.read_csv('data/response_measures/workplace-closures-covid.csv', parse_dates=['date'])\n",
    "df_home = pd.read_csv('data/response_measures/stay-at-home-covid.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = df_stringency.merge(df_internal_movement, on=['country', 'code', 'date'], how='outer')\n",
    "df_targets = df_targets.merge(df_public_gathering, on=['country', 'code', 'date'], how='outer')\n",
    "df_targets = df_targets.merge(df_school, on=['country', 'code', 'date'], how='outer')\n",
    "df_targets = df_targets.merge(df_workplace, on=['country', 'code', 'date'], how='outer')\n",
    "df_targets = df_targets.merge(df_home, on=['country', 'code', 'date'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names of some countries to equal the training data\n",
    "country_mapper = {\n",
    "    'Cape Verde': 'Cabo Verde',\n",
    "    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n",
    "    'Czechia': 'Czech Republic (Czechia)',\n",
    "    'Democratic Republic of Congo': 'DR Congo',\n",
    "    'Palestine': 'State of Palestine',\n",
    "    'Timor': 'Timor-Leste'\n",
    "}\n",
    "df_targets.country = df_targets.country.replace(country_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 88591 entries, 0 to 88590\nData columns (total 9 columns):\n #   Column                           Non-Null Count  Dtype         \n---  ------                           --------------  -----         \n 0   country                          88591 non-null  object        \n 1   code                             88591 non-null  object        \n 2   date                             88591 non-null  datetime64[ns]\n 3   stringency_index                 84403 non-null  float64       \n 4   restrictions_internal_movements  88083 non-null  float64       \n 5   restriction_gatherings           88396 non-null  float64       \n 6   school_closures                  84859 non-null  float64       \n 7   workplace_closures               88367 non-null  float64       \n 8   stay_home_requirements           88099 non-null  float64       \ndtypes: datetime64[ns](1), float64(6), object(2)\nmemory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_targets.info()"
   ]
  },
  {
   "source": [
    "# Training the models\n",
    "### Contact matrix models\n",
    "We now want to train one model for each of the weights we want to predict. For the contact matrices, these are:\n",
    "- **Home**: Weights for the matrix regarding at-home contacts (Target label: *stay_home_requirements*)\n",
    "- **School**: Weights for the matrix regarding school contacts (Target label: *school_closures*)\n",
    "- **Work**: Weights for the matrix regarding at-work contacts (Target label: *workplace_closures*)\n",
    "- **Public**: Weights for the matrix regarding school contacts (Target label: *restriction_gatherings*)\n",
    "\n",
    "### Movement model\n",
    "For the inter region movement, we want to train a model that gives scaling factors given infection/death levels. We have one factor:\n",
    "- **Movement**: Factor for scaling the total movement for the population in the SEAIR-model (Target label: *restrictions_internal_movements*)\n",
    "\n",
    "As the training data contains data on dates where control measures are not recorded, we get NaN-values for the new dataframe. We assume that for the missinng target values, we can fill these with the closest preceeding control measure. We use the pandas fillna() function with method='bfill' to obtain this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions before training\n",
    "def get_model_data(target_label):\n",
    "    df_target = df_targets[['country', 'date', target_label]] # Get relevant target from targets dataframe\n",
    "    df_model = df_training.merge(df_target, on=['country', 'date'], how='left').set_index(['country', 'date']) # Merge training data with target on country and date\n",
    "    df_model.fillna(method='bfill', inplace=True)\n",
    "    return df_model\n",
    "\n",
    "def split_data(df, target_label):\n",
    "    y = df[target_label]\n",
    "    X = df.drop([target_label], axis=1)\n",
    "    X_mat = X.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train, y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = MLPClassifier(random_state=rs, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "def score_model(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "    print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def save_model(fpath_model, fpath_scaler):\n",
    "    pkl.dump(model, open(fpath_model, 'wb'))\n",
    "    pkl.dump(scaler, open(fpath_scaler, 'wb'))"
   ]
  },
  {
   "source": [
    "## Home model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLPClassifier(max_iter=1000, random_state=10)\n",
      "Train accuracy: 0.6173083906336023\n",
      "Test accuracy: 0.6119570819472426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.83      0.73      9601\n",
      "         1.0       0.66      0.20      0.30      4673\n",
      "         2.0       0.53      0.65      0.59      6151\n",
      "         3.0       0.77      0.15      0.25       918\n",
      "\n",
      "    accuracy                           0.61     21343\n",
      "   macro avg       0.65      0.46      0.47     21343\n",
      "weighted avg       0.62      0.61      0.58     21343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_label = 'stay_home_requirements'\n",
    "df_model = get_model_data(target_label)\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(df_model, target_label)\n",
    "model = train_model(X_train, y_train)\n",
    "score_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(fpath_model='models/home_weight_model.sav', fpath_scaler='models/home_weight_scaler.sav')"
   ]
  },
  {
   "source": [
    "## School model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLPClassifier(max_iter=1000, random_state=10)\nTrain accuracy: 0.6016586817228736\nTest accuracy: 0.5940589420418873\n              precision    recall  f1-score   support\n\n         0.0       0.78      0.52      0.62      6230\n         1.0       0.47      0.63      0.53      3733\n         2.0       0.51      0.27      0.35      3770\n         3.0       0.60      0.80      0.69      7610\n\n    accuracy                           0.59     21343\n   macro avg       0.59      0.55      0.55     21343\nweighted avg       0.61      0.59      0.58     21343\n\n"
     ]
    }
   ],
   "source": [
    "target_label = 'school_closures'\n",
    "df_model = get_model_data(target_label)\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(df_model, target_label)\n",
    "model = train_model(X_train, y_train)\n",
    "score_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(fpath_model='models/school_measure_model.sav', fpath_scaler='models/school_measure_scaler.sav')"
   ]
  },
  {
   "source": [
    "## Work model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLPClassifier(max_iter=1000, random_state=10)\nTrain accuracy: 0.599034778432452\nTest accuracy: 0.5992128566743194\n              precision    recall  f1-score   support\n\n         0.0       0.62      0.80      0.70      7674\n         1.0       0.56      0.13      0.21      2997\n         2.0       0.58      0.70      0.63      7964\n         3.0       0.59      0.24      0.34      2708\n\n    accuracy                           0.60     21343\n   macro avg       0.59      0.47      0.47     21343\nweighted avg       0.59      0.60      0.56     21343\n\n"
     ]
    }
   ],
   "source": [
    "target_label = 'workplace_closures'\n",
    "df_model = get_model_data(target_label)\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(df_model, target_label)\n",
    "model = train_model(X_train, y_train)\n",
    "score_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(fpath_model='models/work_measure_model.sav', fpath_scaler='models/work_measure_scaler.sav')"
   ]
  },
  {
   "source": [
    "## Public model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLPClassifier(max_iter=1000, random_state=10)\n",
      "Train accuracy: 0.599034778432452\n",
      "Test accuracy: 0.5992128566743194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.80      0.70      7674\n",
      "         1.0       0.56      0.13      0.21      2997\n",
      "         2.0       0.58      0.70      0.63      7964\n",
      "         3.0       0.59      0.24      0.34      2708\n",
      "\n",
      "    accuracy                           0.60     21343\n",
      "   macro avg       0.59      0.47      0.47     21343\n",
      "weighted avg       0.59      0.60      0.56     21343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_label = 'workplace_closures'\n",
    "df_model = get_model_data(target_label)\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(df_model, target_label)\n",
    "model = train_model(X_train, y_train)\n",
    "score_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(fpath_model='models/public_measure_model.sav', fpath_scaler='models/public_measure_scaler.sav')"
   ]
  },
  {
   "source": [
    "## Movement model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLPClassifier(max_iter=1000, random_state=10)\nTrain accuracy: 0.6795909522191896\nTest accuracy: 0.674319448999672\n              precision    recall  f1-score   support\n\n         0.0       0.68      0.88      0.77     11275\n         1.0       0.57      0.14      0.23      3015\n         2.0       0.67      0.57      0.62      7053\n\n    accuracy                           0.67     21343\n   macro avg       0.64      0.53      0.54     21343\nweighted avg       0.66      0.67      0.64     21343\n\n"
     ]
    }
   ],
   "source": [
    "target_label = 'restrictions_internal_movements'\n",
    "df_model = get_model_data(target_label)\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(df_model, target_label)\n",
    "model = train_model(X_train, y_train)\n",
    "score_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(fpath_model='models/movement_measure_model.sav', fpath_scaler='models/movement_measure_scaler.sav')"
   ]
  }
 ]
}